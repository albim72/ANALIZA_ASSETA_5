# -*- coding: utf-8 -*-
"""zapis_modeli_wag_f.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c1blB7iIVngYkXG7N10MQ1GUOOXr4QVa
"""

!pip install pyyaml h5py

import os
import tensorflow as tf
from tensorflow import keras

print(tf.version.VERSION)

!python --version

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

train_labels = train_labels[:1000]
test_labels = test_labels[:1000]

train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0
test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0

#piszemy funkcję create_model() która pozwoli utworzy model sieci neuronowej o warstwie o gęstości 512
#z dropoutem 0.2, strata: kategoryczna entropia krzyżowa, metryka: accuracy
def create_model():
  model = tf.keras.models.Sequential([
    keras.layers.Dense(512, activation='relu', input_shape=(784,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10,activation='softmax')
  ])

  model.compile(optimizer='adam',
                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])

  return model

model = create_model()
model.summary()

#użycie callbacks w punktach kontrolnych - utworzenie katalogu training_1, w nim pliku cp.ckpt.weights.h5
#zdefiniowanie metody Checkpoint tylko z zapisem wag,
#zdefiniowanie i uruchomienie treningu sieci z użyciem callbacks

checkpoint_path = "training_1/cp.ckpt.weights.h5"
checkpoint_dir = os.path.dirname(checkpoint_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)
model.fit(train_images,
          train_labels,
          epochs=12,
          validation_data=(test_images,test_labels),
          callbacks=[cp_callback])

model = create_model()
loss, acc = model.evaluate(test_images, test_labels)
print("Untrained model, accuracy: {:5.2f}%".format(100 * acc))

model.load_weights(checkpoint_path)
loss, acc = model.evaluate(test_images, test_labels)
print("Restored model, accuracy: {:5.2f}%".format(100 * acc))

checkpoint_path = 'training_2/cp-{epoch:04}.ckpt.weights.h5'
checkpoint_dir = os.path.dirname(checkpoint_path)
batch_size=32

cp_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path,
    verbose=1,
    save_weights_only=True,
    save_freq=5*batch_size)

model = create_model()

os.makedirs(checkpoint_dir, exist_ok=True)
model.save_weights(checkpoint_path.format(epoch=0))

model.fit(train_images,
          train_labels,
          epochs=60,
          batch_size=batch_size,
          callbacks=[cp_callback],
          validation_data=(test_images, test_labels),
          verbose=0)

model = create_model()
loss, acc = model.evaluate(test_images, test_labels, verbose=2)
print("Untrained model, accuracy: {:5.2f}%".format(100 * acc))

model.load_weights('training_2/cp-0060.ckpt.weights.h5')
loss, acc = model.evaluate(test_images, test_labels, verbose=2)
print("Restored model, accuracy: {:5.2f}%".format(100 * acc))

#zapis całego modelu
model = create_model()
model.fit(train_images, train_labels, epochs=10)
model.save('my_model.h5')

new_model = keras.models.load_model('my_model.h5')
new_model.summary()

loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)
print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))